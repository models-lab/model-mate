epochs: 10
scheduler: linear
context_length: 512
batch_size: 2
gradient_accumulation_steps: 16
learning_rate: 5e-5